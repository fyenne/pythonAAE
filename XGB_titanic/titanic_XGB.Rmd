---
title: "titanic"
author: "Siming Yan"
date: "2/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

<!-- ## R Markdown -->
 

```{r cars}
library(caret)
library(tidyverse)
library(xgboost)
library("Matrix")
```


```{r}
load("~/Downloads/booooks/semester5/pythonAAE/XGB_titanic/clean.RData")
# train = read.csv("./train.csv")
# test  = read.csv("./test.csv")
# train_y = read.csv("./target.csv")
# names(train)
# train_y = train$Survived
# train = train[,-2]
train = train[, !names(train) %in% "Name_wiki"]
tests = tests[, !names(tests) %in% "Name_wiki"]

```

```{r}
# dummie = names(train)[!names(train) %in% 
#                         c("Age_wiki", "Parch", "SibSp", "Fare", "Body", "Lifeboat")]
# dummi2 = names(tests)[!names(tests) %in% 
#                         c("Age_wiki", "Parch", "SibSp", "Fare", "Body", "Lifeboat")]
str(train)

cols.num <- c("title","Survived","Sex","Hometown","Boarded","Destination",
              "Lifeboat", "Body", "Class", "alone")
train[cols.num] <- lapply(train[cols.num], as.factor)
# delete survived
tests[cols.num] <- lapply(tests[cols.num], as.factor)

# train$Class = train$Class %>% as.factor()
# train$Ticket_num_len = train$Ticket_num_len %>% as.factor()
# tests$Class = tests$Class %>% as.factor()
# tests$Ticket_num_len = tests$Ticket_num_len %>% as.factor()

# train$Lifeboat = train$Lifeboat %>% as.factor()
# tests$Lifeboat = tests$Lifeboat %>% as.factor()

# train$Lifeboat = na.fill(train$Lifeboat, NA)
# tests$Lifeboat = na.fill(tests$Lifeboat, NA)
# train$Body = na.fill(train$Body, NA)
# tests$Body = na.fill(tests$Body, NA)
#--------------------------------------------

# df_train_d = fastDummies::dummy_cols(train, 
#                                      select_columns = dummie)
# 
# df_test_d  = fastDummies::dummy_cols(tests, 
#                                      select_columns = dummi2)
# 
# df_train_d = df_train_d[, !names(df_train_d) %in% dummie]
# df_test_d  = df_test_d [, !names(df_test_d ) %in% dummi2]
# 
# names(df_train_d)[which(!names(df_train_d) %in% names(df_test_d))]
# df_test_d$Embarked_ = 0
# df_test_d$Cabin2_T  = 0
# df_test_d = df_test_d[,names(df_train_d)]

#--------------------------------------------

df_train_d = train
df_test_d  = tests
```


```{r}
# samplesize = 0.75 * nrow(df_train_d)
# set.seed(15)
# index = sample(nrow(df_train_d),size = samplesize)
# # creating training and test set
# df_train = df_train_d[index,]
# df_valid = df_train_d[-index,]
# d_train_y = train_y[index] %>% data.frame()
# d_valid_y = train_y[-index]%>% data.frame()
```

```{r}
#create tasks
library(mlr)
# df_tr_d_search = cbind(df_train, d_train_y)
# df_te_d_search = cbind(df_valid, d_valid_y)
# names(df_tr_d_search)[15] = "target"
# names(df_te_d_search)[15] = "target"

imp = impute(train, target = "Survived", 
       classes = list(numeric = imputeMedian(),
                      factor  = imputeMode(),
                      character = imputeMode()))

imp$data$title %>% as.factor() %>% str
```

```{r}

soy = createDummyFeatures(imp$data, target="Survived")
tsk = makeClassifTask(data = soy, target="Survived")
ho = makeResampleInstance("Holdout", tsk)
tsk.train = subsetTask(tsk, ho$train.inds[[1]])
tsk.test = subsetTask(tsk, ho$test.inds[[1]])
 


lrn = makeLearner("classif.xgboost",nrounds=10)
cv  = makeResampleDesc("CV",iters=5)
res = resample(lrn,tsk.train,cv,acc)

ps = makeParamSet(makeNumericParam("eta",0,1), 
                  makeNumericParam("lambda",0,200),
                  makeIntegerParam("max_depth",1,20))
tc = makeTuneControlMBO(budget=100)
tr = tuneParams(lrn, tsk.train, cv5, acc, ps, tc)
lrn = setHyperPars(lrn, 
                   par.vals=tr$x)

```

#--------------------------------------------

# random/grid search procedure and attempt to find better accuracy


```{r}

d_valid_y = d_valid_y %>% as.factor()
d_train_y = d_train_y %>% as.factor()
df_tr_d_search = cbind(df_train, d_train_y)
df_te_d_search = cbind(df_valid, d_valid_y)



traintask <- makeClassifTask(data = df_tr_d_search, target = "d_train_y")

#--------------------------------------------
validtask <- makeClassifTask(data = df_te_d_search, target = "d_valid_y")
#--------------------------------------------
test_target = data.frame(d_train_y = rep(0, dim(df_test_d)[1]) %>% as.factor())
df_test_d_search = cbind(df_test_d, test_target)
testtask <- makeClassifTask(data = df_test_d_search, target = 'd_train_y')
```

```{r}
lrn <- makeLearner("classif.xgboost", 
                   predict.type = "response")
lrn$par.vals <- list(objective="binary:logistic", 
                     eval_metric="error", 
                     nrounds=100L, 
                     eta=0.1)
```

```{r}
library(parallel)
library(parallelMap) 
parallelStartSocket(cpus = detectCores())
```

```{r}
#set parameter space
params <- makeParamSet(makeDiscreteParam("booster", values = c("gbtree","gblinear")),
                       makeIntegerParam("max_depth", lower = 1L,upper = 11L),
                       makeNumericParam("min_child_weight", lower = 1L,upper = 10L),
                       makeNumericParam("subsample", lower = 0.5,upper = .95),
                       makeNumericParam("colsample_bytree", lower = 0.5,upper = 1))

#set resampling strategy
rdesc <- makeResampleDesc("CV", iters=10L, stratify = T)
ctrl  <- makeTuneControlRandom(maxit = 125L)
```

#--------------------------------------------
## search!

```{r}
#parameter tuning
mytune <- tuneParams(learner = lrn, 
                     task = traintask, 
                     resampling = rdesc, 
                     measures = acc, 
                     par.set = params, 
                     control = ctrl, 
                     show.info = T)
mytune$y 
mytune$x
mytune
# Op. pars: booster=gbtree; max_depth=1; min_child_weight=2.72; subsample=0.781; colsample_bytree=0.502
# acc.test.mean=0.6168522
```

```{r}
lrn_tune <- setHyperPars(lrn, par.vals = mytune$x)
# saveRDS(lrn_tune, "./tuned_XGB_titanic.rds")
#train model
xgmodel <- train(learner = lrn_tune, task = traintask)
#predict model
# xgpred_v <- predict(xgmodel, validtask)
xgpred <- predict(xgmodel, testtask)
```

```{r}
# confusionMatrix(xgpred$data$response, xgpred$data$truth)
```

```{r}
sub = read.csv("./data/gender_submission.csv")
sub$Survived = xgpred$data$response
write.csv(sub, "./submission_R_XGB_tuned2.csv", row.names = F)
```